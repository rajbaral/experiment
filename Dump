async onUploadScans(): Promise<void> {
  if (!this.scannedDocuments.length || !this.scanDocumentsForm.valid) return;

  this.isUploading = true;
  let allSuccessful = true;

  const batchDescription: string = this.scanDocumentsForm.get('input')?.value || '';
  const sourceType: string = this.scanDocumentsForm.get('multiSelect')?.value?.[0]?.value || '';

  for (const doc of this.scannedDocuments) {
    const fileName = doc.name;
    const base64Data = doc.url.replace('data:application/pdf;base64,', '');
    this.uploadProgressMap[fileName] = 0;

    try {
      await this.uploadScanService.uploadPdfInChunksWithProgress(
        base64Data,
        fileName,
        (progress) => this.uploadProgressMap[fileName] = progress,
        batchDescription,
        sourceType
      );
    } catch (err) {
      allSuccessful = false;
      console.error(`Upload failed for ${fileName}:`, err);
    }
  }

  this.isUploading = false;

  if (allSuccessful) {
    this.showSuccessNotification('All uploads complete.', 'success');
  } else {
    this.showSuccessNotification('Some documents failed to upload. Please try again.', 'error');
  }
}



import { HttpClient } from '@angular/common/http';
import { Injectable } from '@angular/core';
import { v4 as uuidv4 } from 'uuid';

@Injectable({ providedIn: 'root' })
export class UploadScanService {
  private readonly apiUrl = '/api/uploadfile';

  constructor(private http: HttpClient) {}

  async uploadPdfInChunksWithProgress(
    base64: string,
    originalFileName: string,
    onProgress: (percent: number) => void,
    batchDescription: string,
    sourceType: string
  ): Promise<void> {
    const blob = this.base64ToBlob(base64, 'application/pdf');
    const chunks = this.splitBlob(blob, 2 * 1024 * 1024);
    const totalChunks = chunks.length;
    const guid = uuidv4();
    const fileId = `${guid}_${originalFileName.replace(/\.pdf$/i, '')}`;

    let uploaded = 0;

    for (let i = 0; i < totalChunks; i++) {
      await this.uploadChunkWithRetry(chunks[i], fileId, i, totalChunks, batchDescription, sourceType);
      uploaded++;
      onProgress(Math.floor((uploaded / totalChunks) * 100));
    }
  }

  private async uploadChunkWithRetry(
    chunk: Blob,
    fileId: string,
    chunkIndex: number,
    totalChunks: number,
    batchDescription: string,
    sourceType: string
  ): Promise<void> {
    const formData = new FormData();
    const pdfChunk = new File(
      [chunk],
      `${fileId}_chunk${chunkIndex}.pdf`,
      { type: 'application/pdf' }
    );

    formData.append('file', pdfChunk); // Required by backend IFormFile
    formData.append('fileId', fileId);
    formData.append('chunkIndex', chunkIndex.toString());
    formData.append('totalChunks', totalChunks.toString());
    formData.append('last-chunk', (chunkIndex === totalChunks - 1).toString());
    formData.append('current-chunk', chunkIndex.toString());

    // âœ… Additional fields for DB
    formData.append('batchDescription', batchDescription);
    formData.append('sourceType', sourceType);

    const maxRetries = 3;
    let attempts = 0;

    while (attempts < maxRetries) {
      try {
        await this.http.post(this.apiUrl, formData).toPromise();
        return;
      } catch (err) {
        attempts++;
        if (attempts >= maxRetries) {
          throw new Error(`Chunk ${chunkIndex} failed after ${maxRetries} retries.`);
        }
        await new Promise((res) => setTimeout(res, 1000));
      }
    }
  }

  private base64ToBlob(base64: string, mime: string): Blob {
    const byteCharacters = atob(base64);
    const byteArrays = [];

    for (let offset = 0; offset < byteCharacters.length; offset += 512) {
      const slice = byteCharacters.slice(offset, offset + 512);
      const byteNumbers = Array.from(slice).map((char) => char.charCodeAt(0));
      byteArrays.push(new Uint8Array(byteNumbers));
    }

    return new Blob(byteArrays, { type: mime });
  }

  private splitBlob(blob: Blob, chunkSize: number): Blob[] {
    const chunks: Blob[] = [];
    let offset = 0;

    while (offset < blob.size) {
      const end = Math.min(offset + chunkSize, blob.size);
      chunks.push(blob.slice(offset, end));
      offset = end;
    }

    return chunks;
  }
}



Perfect â€” hereâ€™s the enhanced Angular solution for your scan upload flow with:
	1.	Progress bar for each scanned file
	2.	Disable the Upload button during upload
	3.	Retry logic for failed chunks (with 3 attempts max)

â¸»

Step-by-Step Enhanced Implementation

â¸»

1. Extend ScanUploadService with Progress + Retry

@Injectable({ providedIn: 'root' })
export class ScanUploadService {
  constructor(private http: HttpClient) {}

  async uploadPdfInChunksWithProgress(
    base64: string,
    fileName: string,
    onProgress: (percent: number) => void
  ): Promise<void> {
    const blob = this.base64ToBlob(base64, 'application/pdf');
    const chunks = this.splitBlob(blob, 2 * 1024 * 1024);
    const totalChunks = chunks.length;
    const fileId = fileName;

    let uploaded = 0;

    for (let i = 0; i < totalChunks; i++) {
      await this.uploadChunkWithRetry(chunks[i], fileId, i, totalChunks);
      uploaded++;
      onProgress(Math.floor((uploaded / totalChunks) * 100));
    }
  }

  private async uploadChunkWithRetry(chunk: Blob, fileId: string, chunkIndex: number, totalChunks: number) {
    const formData = new FormData();
    formData.append('fileId', fileId);
    formData.append('chunkIndex', chunkIndex.toString());
    formData.append('totalChunks', totalChunks.toString());
    formData.append('chunk', chunk, `${fileId}_chunk${chunkIndex}.part`);

    let attempts = 0;
    const maxRetries = 3;

    while (attempts < maxRetries) {
      try {
        await this.http.post('/api/upload-chunk', formData).toPromise();
        return;
      } catch (err) {
        attempts++;
        if (attempts >= maxRetries) {
          throw new Error(`Chunk ${chunkIndex} failed after ${maxRetries} retries.`);
        }
        await new Promise(res => setTimeout(res, 1000)); // wait before retry
      }
    }
  }

  private base64ToBlob(base64: string, mime: string): Blob {
    const byteCharacters = atob(base64);
    const byteArrays = [];

    for (let offset = 0; offset < byteCharacters.length; offset += 512) {
      const slice = byteCharacters.slice(offset, offset + 512);
      const byteNumbers = Array.from(slice).map(char => char.charCodeAt(0));
      byteArrays.push(new Uint8Array(byteNumbers));
    }

    return new Blob(byteArrays, { type: mime });
  }

  private splitBlob(blob: Blob, chunkSize: number): Blob[] {
    const chunks: Blob[] = [];
    let offset = 0;

    while (offset < blob.size) {
      const end = Math.min(offset + chunkSize, blob.size);
      chunks.push(blob.slice(offset, end));
      offset = end;
    }

    return chunks;
  }
}


â¸»

2. Update ScanDocumentComponent for Upload Logic

Add UI state variables:

isUploading = false;
uploadProgressMap: { [fileName: string]: number } = {};

Update your onUploadScans() method:

async onUploadScans(): Promise<void> {
  if (!this.scannedDocuments.length) return;

  this.isUploading = true;

  for (let doc of this.scannedDocuments) {
    const fileName = doc.name;
    const base64Data = doc.url.replace('data:application/pdf;base64,', '');
    this.uploadProgressMap[fileName] = 0;

    try {
      await this.scanUploadService.uploadPdfInChunksWithProgress(
        base64Data,
        fileName,
        (progress: number) => {
          this.uploadProgressMap[fileName] = progress;
        }
      );
    } catch (err) {
      console.error(`Upload failed for ${fileName}:`, err);
      alert(`Upload failed for ${fileName}: ${err.message}`);
    }
  }

  this.isUploading = false;
  alert('All uploads complete.');
}


â¸»

3. Update the HTML Template

Disable button and show progress:

<button [disabled]="isUploading" (click)="onUploadScans()">Upload Scans</button>

<div *ngFor="let doc of scannedDocuments">
  <div>{{ doc.name }}</div>
  <progress [value]="uploadProgressMap[doc.name] || 0" max="100"></progress>
</div>


â¸»

All Set

Now you have:
	â€¢	Upload progress per file
	â€¢	Retry logic per chunk (3 attempts)
	â€¢	Button disabled while uploading



Great question â€” hereâ€™s the clear and direct answer:

â¸»

Does Asprise Scanner.js provide chunking functionality?

No, Scanner.js does not handle chunking or uploading large files out-of-the-box.

It:
	â€¢	Handles device communication (TWAIN/WIA),
	â€¢	Provides UI for preview/editing scanned pages,
	â€¢	Returns output as Base64, Blob, or file download (PDF/JPEG).

â¸»

Why weâ€™re handling chunking manually?

Because:
	1.	Browser upload limits (especially with large PDFs/images) â€” uploads can fail due to timeout, size, or memory.
	2.	Reliability â€” chunking with retry lets you resume part of an upload instead of failing the whole file.
	3.	Scalability â€” Azure Blob Storage (and most cloud providers) recommends chunked/multipart uploads for files over ~4MB.

â¸»

Best Practice Summary
	â€¢	Scanner.js: Great for capture + preview
	â€¢	Angular (frontend): Responsible for:
	â€¢	Handling large files
	â€¢	Splitting into chunks
	â€¢	Retry + upload control
	â€¢	Backend: Responsible for assembling chunks + pushing to storage

This decoupled pattern is standard practice in modern apps (used by Dropbox, Google Drive, Azure Storage SDKs, etc.)

â¸»

Let me know if you want to compare this with Azure SDKâ€™s own chunk upload (e.g., direct-to-blob via BlockBlobClient) â€” thatâ€™s another option if youâ€™re using SAS tokens.



async onUploadScans(): Promise<void> {
  if (!this.scannedDocuments.length) return;

  this.isUploading = true;
  let allSuccessful = true;

  for (let doc of this.scannedDocuments) {
    const fileName = doc.name;
    const base64Data = doc.url.replace('data:application/pdf;base64,', '');
    this.uploadProgressMap[fileName] = 0;

    try {
      await this.scanUploadService.uploadPdfInChunksWithProgress(
        base64Data,
        fileName,
        (progress: number) => {
          this.uploadProgressMap[fileName] = progress;
        }
      );
    } catch (err) {
      allSuccessful = false;
      console.error(`Upload failed for ${fileName}:`, err);
      alert(`Upload failed for ${fileName}: ${err.message}`);
    }
  }

  this.isUploading = false;

  if (allSuccessful) {
    alert('All uploads complete.');
  } else {
    alert('Some documents failed to upload. Please check the console or try again.');
  }
}



.upload-progress-wrapper {
  margin-bottom: 1rem;
  .file-label {
    font-size: 14px;
    margin-bottom: 4px;
    font-weight: 600;
    color: #333;
  }

  .progress-bar {
    width: 100%;
    height: 20px;
    background-color: #e0e0e0;
    border-radius: 10px;
    overflow: hidden;
    position: relative;

    .progress-fill {
      background-color: #4caf50;
      height: 100%;
      width: 0;
      color: #fff;
      font-size: 12px;
      font-weight: 600;
      text-align: right;
      padding-right: 8px;
      line-height: 20px;
      border-radius: 10px 0 0 10px;
      transition: width 0.3s ease;

      .progress-text {
        position: absolute;
        right: 10px;
        top: 0;
        line-height: 20px;
      }
    }
  }
}


<div *ngFor="let doc of scannedDocuments" class="upload-progress-wrapper">
  <div class="file-label">{{ doc.name }}</div>
  <div class="progress-bar">
    <div class="progress-fill" [style.width.%]="uploadProgressMap[doc.name] || 0">
      <span class="progress-text">
        {{ uploadProgressMap[doc.name] || 0 }}%
      </span>
    </div>
  </div>
</div>



Here is your final drop-in Angular upload service method that works perfectly with your current .NET backend, and resolves the Unsupported file type error.

â¸»

âœ… Final UploadScanService Method

Replace your uploadPdfInChunksWithProgress() and uploadChunkWithRetry() with the following:

ðŸ”§ uploadPdfInChunksWithProgress()

async uploadPdfInChunksWithProgress(
  base64: string,
  fileName: string,
  onProgress: (percent: number) => void
): Promise<void> {
  const blob = this.base64ToBlob(base64, 'application/pdf');
  const chunks = this.splitBlob(blob, 2 * 1024 * 1024);
  const totalChunks = chunks.length;
  const fileId = fileName;

  let uploaded = 0;

  for (let i = 0; i < totalChunks; i++) {
    await this.uploadChunkWithRetry(chunks[i], fileId, i, totalChunks);
    uploaded++;
    onProgress(Math.floor((uploaded / totalChunks) * 100));
  }
}


â¸»

ðŸ”§ uploadChunkWithRetry()

private async uploadChunkWithRetry(
  chunk: Blob,
  fileId: string,
  chunkIndex: number,
  totalChunks: number
): Promise<void> {
  const formData = new FormData();

  // âœ… Wrap chunk in File object to set correct Content-Type
  const pdfChunk = new File([chunk], `${fileId}_chunk${chunkIndex}.pdf`, {
    type: 'application/pdf'
  });

  formData.append('fileId', fileId);
  formData.append('chunkIndex', chunkIndex.toString());
  formData.append('totalChunks', totalChunks.toString());
  formData.append('file', pdfChunk); // âœ… Backend expects this as IFormFile
  formData.append('last-chunk', (chunkIndex === totalChunks - 1).toString());
  formData.append('current-chunk', chunkIndex.toString());

  const maxRetries = 3;
  let attempts = 0;

  while (attempts < maxRetries) {
    try {
      await this.http.post('/api/uploadfile', formData).toPromise();
      return;
    } catch (err) {
      attempts++;
      if (attempts >= maxRetries) {
        throw new Error(`Chunk ${chunkIndex} failed after ${maxRetries} retries.`);
      }
      await new Promise((res) => setTimeout(res, 1000)); // wait before retry
    }
  }
}


â¸»

ðŸ’¡ Supporting Methods (if not already defined)

private base64ToBlob(base64: string, mime: string): Blob {
  const byteCharacters = atob(base64);
  const byteArrays = [];

  for (let offset = 0; offset < byteCharacters.length; offset += 512) {
    const slice = byteCharacters.slice(offset, offset + 512);
    const byteNumbers = Array.from(slice).map((char) => char.charCodeAt(0));
    byteArrays.push(new Uint8Array(byteNumbers));
  }

  return new Blob(byteArrays, { type: mime });
}

private splitBlob(blob: Blob, chunkSize: number): Blob[] {
  const chunks: Blob[] = [];
  let offset = 0;

  while (offset < blob.size) {
    const end = Math.min(offset + chunkSize, blob.size);
    chunks.push(blob.slice(offset, end));
    offset = end;
  }

  return chunks;
}


â¸»

âœ… This Resolves:
	â€¢	400 Bad Request â€” missing or invalid file
	â€¢	"Unsupported file type" â€” incorrect or missing MIME
	â€¢	Ensures .NET receives:
	â€¢	IFormFile file with proper ContentType
	â€¢	Required headers: last-chunk, current-chunk
	â€¢	PDF chunks named with .pdf

â¸»

Let me know if you want the full working UploadScanService.ts file or integration into your onUploadScans() logic.
